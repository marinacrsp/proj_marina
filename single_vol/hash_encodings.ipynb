{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Embedding(400, 2)\n",
      "  (1): Embedding(676, 2)\n",
      "  (2): Embedding(1225, 2)\n",
      "  (3): Embedding(2209, 2)\n",
      "  (4-9): 6 x Embedding(4096, 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "L = 10\n",
    "n_inputs_dim = 2\n",
    "log2_hashmap_size = 12 # NOTE : This is the size of the hashtable (T)\n",
    "\n",
    "n_features_per_level = 2\n",
    "Nmax = 320\n",
    "Nmin = 16\n",
    "\n",
    "b = np.exp((np.log(Nmax)-np.log(Nmin))/(L-1))\n",
    "\n",
    "def _get_number_of_embeddings(level_idx: int) -> int:\n",
    "    \"\"\"\n",
    "    level_idx: level index\n",
    "    returns: number of embeddings for given level. Max number is 2**self.log2_hashmap_size\n",
    "    \"\"\"\n",
    "\n",
    "    max_size = 2**log2_hashmap_size\n",
    "\n",
    "    resolution = int(Nmin * (b**level_idx).item())\n",
    "    \n",
    "    n_level_size = (resolution + 4) ** 2  # see explanation below at 'def _to_1D(...)' why we do + 2\n",
    "\n",
    "    return min(max_size, n_level_size)\n",
    "\n",
    "embeddings = nn.ModuleList(\n",
    "    [\n",
    "        nn.Embedding(\n",
    "            _get_number_of_embeddings([i]), n_features_per_level\n",
    "        )\n",
    "        for i in range(L)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(embeddings)\n",
    "\n",
    "\n",
    "#### Functions required for hash_encoding\n",
    "\n",
    "def bilinear_interp(\n",
    "    x: torch.Tensor,\n",
    "    box_indices: torch.Tensor,\n",
    "    box_embedds: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Function that computes the bilinear interpolation of the embedding for a point in a bounding box of identified corners\n",
    "    \"\"\"\n",
    "    if box_indices.shape[0] > 2:\n",
    "        w11 = np.linalg.norm(box_indices[0] - x)\n",
    "        w12 = np.linalg.norm(box_indices[1] - x)\n",
    "        w21 = np.linalg.norm(box_indices[2] - x)\n",
    "        w22 = np.linalg.norm(box_indices[3] - x)\n",
    "\n",
    "        den = w11+w12+w21+w22\n",
    "\n",
    "        w11 /= den\n",
    "        w12 /= den\n",
    "        w21 /= den\n",
    "        w22 /= den\n",
    "\n",
    "        xi_embedding = w11*box_embedds[0] + w12*box_embedds[1] + w21*box_embedds[2] + w22*box_embedds[3]  \n",
    "        \n",
    "    else:\n",
    "        xi_embedding = box_embedds\n",
    "        \n",
    "    return xi_embedding\n",
    "\n",
    "\n",
    "def _get_box_idx (point, Nmax, resolution, log2_hashmap_size):\n",
    "    x, y = point\n",
    "\n",
    "    if Nmax == resolution:\n",
    "        box_idx = torch.tensor((point[0], point[1]))\n",
    "\n",
    "    else:\n",
    "        # Calculate box size based on the total boxes\n",
    "        box_width = Nmax // resolution  # Width of each box\n",
    "        box_height = Nmax // resolution  # Height of each box\n",
    "\n",
    "        x_min = max(0, (x // box_width) * box_width)\n",
    "        y_min = max(0, (y // box_height) * box_height)\n",
    "        x_max = min(Nmax, x_min + box_width)\n",
    "        y_max = min(Nmax, y_min + box_height)\n",
    "        \n",
    "        \n",
    "        p00 = [x_min, y_min]\n",
    "        p01 = [x_max, y_min]\n",
    "        p10 = [x_min, y_max]\n",
    "        p11 = [x_max, y_max]\n",
    "        \n",
    "        box_idx = torch.tensor((p00, p01, p10, p11))\n",
    "        \n",
    "    max_hashtable_size = 2**log2_hashmap_size\n",
    "    if max_hashtable_size > resolution**2:\n",
    "        hashed_box_idx, scaled_coords = _to_1D(box_idx, Nmax, resolution)\n",
    "    else:\n",
    "        hashed_box_idx = _hash(box_idx, log2_hashmap_size)\n",
    "        \n",
    "    return box_idx, hashed_box_idx\n",
    "\n",
    "def _to_1D(coors, Nmax, resolution):\n",
    "    scale_factor = Nmax // resolution\n",
    "    scaled_coords = torch.div(coors, scale_factor, rounding_mode=\"floor\").int()    \n",
    "    x = scaled_coords[:,0]\n",
    "    y = scaled_coords[:,1]\n",
    "    \n",
    "    return (y * resolution + x), scaled_coords\n",
    "\n",
    "def _hash(coords: torch.Tensor, log2_hashmap_size: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    coords: this function can process upto 7 dim coordinates\n",
    "    log2T:  logarithm of T w.r.t 2\n",
    "    \"\"\"\n",
    "    primes = torch.tensor([\n",
    "        1,\n",
    "        2654435761,\n",
    "        805459861,\n",
    "        3674653429,\n",
    "        2097192037,\n",
    "        1434869437,\n",
    "        2165219737,\n",
    "    ], dtype = torch.int64\n",
    "    )\n",
    "\n",
    "    xor_result = torch.zeros_like(coords, dtype=torch.int64)[..., 0]\n",
    "    for i in range(coords.shape[-1]): # Loop around all possible dimensions of the vector containing the bounding box positions\n",
    "        xor_result ^= coords[...,i].to(torch.int64)*primes[i]\n",
    "\n",
    "    return (\n",
    "        torch.tensor((1 << log2_hashmap_size) - 1, device=xor_result.device)\n",
    "        & xor_result\n",
    "        )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "22\n",
      "31\n",
      "43\n",
      "60\n",
      "84\n",
      "117\n",
      "164\n",
      "229\n",
      "320\n",
      "tensor([ 0.5554, -0.7761,  0.4109,  1.1651,  0.8021, -1.1589, -0.9328,  1.0611,\n",
      "        -0.3175,  0.6355, -0.5556, -0.0240,  0.5324,  0.0339, -0.4623, -0.5715,\n",
      "         0.2971,  0.4746,  0.5212,  1.7220], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "point = torch.tensor([319,319])\n",
    "x_embedded_all = []\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    print(resolution)\n",
    "    box_idx, hashed_box_idx = _get_box_idx(point, Nmax, resolution, log2_hashmap_size)\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded = bilinear_interp(point, box_idx, box_embedds)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "22\n",
      "31\n",
      "43\n",
      "60\n",
      "84\n",
      "117\n",
      "164\n",
      "229\n",
      "320\n",
      "tensor([ 0.4948, -0.6677,  0.4109,  1.1651,  0.6012, -0.9509, -1.4937,  0.5453,\n",
      "        -0.3050, -0.0969, -0.9447, -0.5184, -0.6131, -0.4333,  1.2609, -0.0287,\n",
      "        -0.6124, -0.7133, -0.8770,  2.7351], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "point = torch.tensor([310, 317])\n",
    "x_embedded_all = []\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    print(resolution)\n",
    "    box_idx, hashed_box_idx = _get_box_idx(point, Nmax, resolution, log2_hashmap_size)\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded = bilinear_interp(point, box_idx, box_embedds)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "22\n",
      "31\n",
      "43\n",
      "60\n",
      "84\n",
      "117\n",
      "164\n",
      "229\n",
      "320\n",
      "tensor([ 0.8431,  0.2460,  0.4135,  0.3757, -0.2419, -0.0620, -0.4686, -1.2061,\n",
      "        -0.0622,  0.1241,  0.3490,  1.3119,  0.0768, -0.1606,  0.4591, -0.5743,\n",
      "        -0.2125,  0.3595,  0.7171, -2.1822], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "point = torch.tensor([0, 0])\n",
    "x_embedded_all = []\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    print(resolution)\n",
    "    box_idx, hashed_box_idx = _get_box_idx(point, Nmax, resolution, log2_hashmap_size)\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded = bilinear_interp(point, box_idx, box_embedds)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "22\n",
      "31\n",
      "43\n",
      "60\n",
      "84\n",
      "117\n",
      "164\n",
      "229\n",
      "320\n",
      "tensor([-0.0125, -0.3245, -0.4046,  0.6017,  0.1132, -0.6288,  0.0319,  0.0631,\n",
      "         0.3316, -0.3720,  0.3281, -0.6362,  0.4788, -0.9974,  1.3093, -0.3233,\n",
      "         0.9508, -1.0356, -0.5815, -0.3331], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "point = torch.tensor([120, 120])\n",
    "x_embedded_all = []\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    print(resolution)\n",
    "    box_idx, hashed_box_idx = _get_box_idx(point, Nmax, resolution, log2_hashmap_size)\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded = bilinear_interp(point, box_idx, box_embedds)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [20,  0],\n",
      "        [ 0, 20],\n",
      "        [20, 20]])\n",
      "tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "tensor([[ 0,  0],\n",
      "        [14,  0],\n",
      "        [ 0, 14],\n",
      "        [14, 14]])\n",
      "tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "tensor([[ 0,  0],\n",
      "        [10,  0],\n",
      "        [ 0, 10],\n",
      "        [10, 10]])\n",
      "tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "tensor([[0, 0],\n",
      "        [7, 0],\n",
      "        [0, 7],\n",
      "        [7, 7]])\n",
      "tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "tensor([[0, 0],\n",
      "        [5, 0],\n",
      "        [0, 5],\n",
      "        [5, 5]])\n",
      "tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "tensor([[0, 0],\n",
      "        [3, 0],\n",
      "        [0, 3],\n",
      "        [3, 3]])\n",
      "tensor([[0, 0],\n",
      "        [3, 0],\n",
      "        [0, 3],\n",
      "        [3, 3]])\n",
      "tensor([[0, 0],\n",
      "        [2, 0],\n",
      "        [0, 2],\n",
      "        [2, 2]])\n",
      "tensor([[0, 0],\n",
      "        [2, 0],\n",
      "        [0, 2],\n",
      "        [2, 2]])\n",
      "tensor([[1, 1],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [2, 2]])\n",
      "tensor([[1, 1],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [2, 2]])\n",
      "tensor([[1, 1],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [2, 2]])\n",
      "tensor([[1, 1],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [2, 2]])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4450,  0.3627, -0.7832,  0.6388,  0.2325,  0.7201,  0.2879,  0.6227,\n",
       "         0.4419, -0.2468,  0.4043, -0.5034, -0.1639, -0.4500,  0.0418,  0.8081,\n",
       "         0.6485,  1.2017,  0.4955,  0.5192], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hash_encoding import *\n",
    "point = torch.tensor([1,1])\n",
    "\n",
    "embedder = hash_encoder(levels=10, log2_hashmap_size=12, n_features_per_level=2, n_max = 320, n_min = 16)\n",
    "\n",
    "embedder(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytcu11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

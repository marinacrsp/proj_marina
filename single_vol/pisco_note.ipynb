{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training w/o center\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import *\n",
    "from data_utils import *\n",
    "from fastmri.data.subsample import EquiSpacedMaskFunc, RandomMaskFunc\n",
    "from fastmri.data.transforms import tensor_to_complex_np, to_tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import config\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "file_data = '/itet-stor/mcrespo/bmicdatasets-originals/Originals/fastMRI/brain/multicoil_train/file_brain_AXT1POST_203_6000861.h5'\n",
    "dataset = KCoordDataset(file_data, n_slices=3, n_volumes=1, with_mask=True, acceleration=3, center_frac=0.15, mask_type='Random')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmri.data.transforms import tensor_to_complex_np, to_tensor\n",
    "\n",
    "vol_id = 0\n",
    "file = file_data\n",
    "n_volumes = 1\n",
    "n_slices = 1\n",
    "with_mask = False\n",
    "acceleration = 3\n",
    "center_frac = 0.15\n",
    "mask_type = 'Random'\n",
    "\n",
    "\n",
    "with h5py.File(file, \"r\") as hf:\n",
    "    volume_kspace = to_tensor(preprocess_kspace(hf[\"kspace\"][()]))[:n_slices]\n",
    "\n",
    "##################################################\n",
    "# Mask creation\n",
    "##################################################\n",
    "if mask_type == \"Random\":\n",
    "    mask_func = RandomMaskFunc(\n",
    "    center_fractions=[center_frac], accelerations=[acceleration]\n",
    ")\n",
    "elif mask_type == \"Equispaced\": \n",
    "    mask_func = EquiSpacedMaskFunc(\n",
    "    center_fractions=[center_frac], accelerations=[acceleration])\n",
    "    \n",
    "shape = (1,) * len(volume_kspace.shape[:-3]) + tuple(\n",
    "    volume_kspace.shape[-3:])\n",
    "mask, _ = mask_func(\n",
    "    shape, None, vol_id\n",
    ")  # use the volume index as random seed.\n",
    "\n",
    "# mask, left_idx, right_idx = remove_center(mask)\n",
    "_, left_idx, right_idx = remove_center(mask)  # NOTE: Uncomment to include the center region in the training data. Note that 'left_idx' and 'right_idx' are still needed.\n",
    "\n",
    "##################################################\n",
    "# Computing the indices\n",
    "##################################################\n",
    "n_slices, n_coils, height, width = volume_kspace.shape[:-1]\n",
    "if with_mask:\n",
    "    kx_ids = torch.where(mask.squeeze())[0]\n",
    "else:\n",
    "    kx_ids = torch.arange(width)\n",
    "    # kx_ids = torch.from_numpy(np.setdiff1d(np.arange(width), np.arange(left_idx, right_idx))) # NOTE: Uncomment to include all the datapoints (fully-sampled volume), with the exception of the center region.\n",
    "ky_ids = torch.arange(height)\n",
    "kz_ids = torch.arange(n_slices)\n",
    "coil_ids = torch.arange(n_coils)\n",
    "\n",
    "kspace_ids = torch.meshgrid(kx_ids, ky_ids, coil_ids, indexing=\"ij\")\n",
    "kspace_ids = torch.stack(kspace_ids, dim=-1).reshape(-1, len(kspace_ids))\n",
    "\n",
    "##################################################\n",
    "# Computing the inputs\n",
    "##################################################\n",
    "# Convert indices into normalized coordinates in [-1, 1].\n",
    "kspace_coords = torch.zeros((kspace_ids.shape[0], 3), dtype=torch.float)\n",
    "kspace_coords[:, 0] = (2 * kspace_ids[:, 0]) / (width - 1) - 1\n",
    "kspace_coords[:, 1] = (2 * kspace_ids[:, 1]) / (height - 1) - 1\n",
    "kspace_coords[:, 2] = (2 * kspace_ids[:, 2]) / (n_coils - 1) - 1\n",
    "# kspace_coords[:, 3] = (2 * kspace_ids[:, 3]) / (n_coils - 1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_idx\n",
    "right_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_center_idx = kx_ids[left_idx:right_idx]\n",
    "mask_kx = torch.ones(kx_ids.shape)\n",
    "mask_kx[not_center_idx] = 0\n",
    "\n",
    "kx_new = kx_ids.clone()\n",
    "kx_new = torch.where(mask_kx.squeeze())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize (data, norm_factor):\n",
    "    \"\"\"Function that normalizes a data matrix to the range [-1,1]\"\"\"\n",
    "    n_data = (2*data) / (norm_factor - 1) - 1 \n",
    "    return n_data\n",
    "\n",
    "def denormalize (n_data, norm_factor):\n",
    "    \"\"\"Function that reverts a normalized data matrix to the original range, specified by norm_factor\"\"\"\n",
    "    data = ((n_data + 1) * (norm_factor - 1))/2\n",
    "    return data\n",
    "\n",
    "def split_batch (data, size_minibatch):\n",
    "    \"\"\"Function that performs the random spliting of the dataloader batch into Ns subsets of generally the same size\"\"\"\n",
    "    total_batch = data.shape[0]\n",
    "    iter = total_batch//size_minibatch\n",
    "    sample_batch = []\n",
    "    last_idx = 0\n",
    "    \n",
    "    for i in range(iter):\n",
    "        if i == 0:\n",
    "            minibatch = data[:size_minibatch,...]\n",
    "        elif i==iter-1:\n",
    "            minibatch = data[last_idx+1:,...]\n",
    "        else:\n",
    "            minibatch = data[last_idx+1:last_idx+size_minibatch,...]\n",
    "        \n",
    "        sample_batch.append(minibatch)\n",
    "        last_idx += size_minibatch\n",
    "    return sample_batch, iter\n",
    "\n",
    "def compute_Lsquares (X, Y, alpha):\n",
    "    \"\"\"Solves the Least Squares giving matrix W\"\"\"\n",
    "    P_TxP = torch.matmul(X.T, X)\n",
    "    P_TxT = torch.matmul(X.T, Y)\n",
    "\n",
    "    reg = alpha * torch.eye(P_TxP.shape[0])\n",
    "    W = torch.linalg.solve(P_TxP + reg, P_TxT)\n",
    "    return W\n",
    "\n",
    "def complex_distance(W1, W2):\n",
    "    \"\"\"\n",
    "    Computes the L2 distance between two complex matrices W1 and W2.\n",
    "    It compares both real and imaginary parts.\n",
    "    \"\"\"\n",
    "    # Separate real and imaginary parts\n",
    "    W1_real, W1_imag = W1.real, W1.imag\n",
    "    W2_real, W2_imag = W2.real, W2.imag\n",
    "\n",
    "    # Compute the squared differences for both real and imaginary parts\n",
    "    real_diff = torch.norm(W1_real - W2_real) ** 2\n",
    "    # print(real_diff)\n",
    "    imag_diff = torch.norm(W1_imag - W2_imag) ** 2\n",
    "    # print(imag_diff)\n",
    "\n",
    "    # Return the combined distance\n",
    "    return real_diff + imag_diff\n",
    "\n",
    "\n",
    "def L_pisco (Ws):\n",
    "    \"\"\"Function to compute the Pisco loss\n",
    "    Inputs:\n",
    "    - Ws (list) : contains the corresponding Ws computed from Least squares\n",
    "    \n",
    "    \"\"\"\n",
    "    # Compare the Ws, obtain the Pisco loss\n",
    "    total_loss = 0\n",
    "    Ns = len(Ws)\n",
    "    for i in range(Ns):\n",
    "        for j in range(Ns):\n",
    "            if i!=j:\n",
    "                diff = Ws[i].flatten() - Ws[j].flatten()\n",
    "                pisco = torch.linalg.norm(diff,ord=2)\n",
    "                total_loss += pisco\n",
    "                \n",
    "    return (1/Ns**2) * total_loss\n",
    "\n",
    "def get_grappa_matrixes (inputs, shape):\n",
    "    \"\"\"Function that generates two matrixes out of the input coordinates of the batch points     \n",
    "    - n_r_kcoors : normalized and reshaped matrix containing the kspace coordinates \n",
    "        dim -> (Nm x Nc x 4)\n",
    "    - n_r_patch : normalized and reshaped matrix containing the kspace coordinates of the neighbourhood for each point in first matrix\n",
    "        dim -> (NmÂ·Nn x Nc x 4)\n",
    "    \"\"\"\n",
    "    n_slices, n_coils, height, width = shape\n",
    "    k_coors = torch.zeros((inputs.shape[0], 4), dtype=torch.float)\n",
    "    k_coors[:,0] = denormalize(inputs[:,0], width)\n",
    "    k_coors[:,1] = denormalize(inputs[:,1], height)\n",
    "    k_coors[:,2] = denormalize(inputs[:,2], n_slices)\n",
    "    k_coors[:,3] = denormalize(inputs[:,3], n_coils)\n",
    "\n",
    "    #### Reshape:\n",
    "    # Reshape input matrixes for coilID to be considered dim : n_points x N_coils x 4\n",
    "    r_kcoors = np.repeat(k_coors[:, np.newaxis, :], n_coils, axis=1)\n",
    "    r_kcoors[...,-1] = torch.arange(n_coils)\n",
    "\n",
    "    \n",
    "    ##### Reshape patches matrix to : n_points x n_neighbours x N_coils x 4\n",
    "    build_neighbours = get_patch()\n",
    "    patch_coors = build_neighbours(r_kcoors)\n",
    "    \n",
    "    # Reshape so that dim : n_points x N_n x Nc x 4 (kx,ky,kz, n_coils coordinates)\n",
    "    r_patch = torch.zeros((patch_coors.shape[0],patch_coors.shape[1], r_kcoors.shape[2]))\n",
    "    r_patch[...,:3] = patch_coors\n",
    "    r_patch = np.repeat(r_patch[:, :, np.newaxis], n_coils, axis=2)\n",
    "    r_patch[...,-1] = torch.arange(n_coils)\n",
    "\n",
    "    ### For predicting, normalize coordinates back to [-1,1]\n",
    "    # Normalize the NP neighbourhood coordinates\n",
    "    n_r_patch = torch.zeros((r_patch.shape), dtype=torch.float)\n",
    "    n_r_patch[:,:,:,0] = normalize(r_patch[:,:,:,0], width)\n",
    "    n_r_patch[:,:,:,1] = normalize(r_patch[:,:,:,1], height)\n",
    "    n_r_patch[:,:,:,2] = normalize(r_patch[:,:,:,2], n_slices)\n",
    "    n_r_patch[:,:,:,3] = normalize(r_patch[:,:,:,3], n_coils)\n",
    "    # Flatten the first dimensions for the purpose of kvalue prediction\n",
    "    Nn = n_r_patch.shape[1]\n",
    "    n_r_patch = n_r_patch.view(-1, n_coils, 4)\n",
    "\n",
    "    # Normalize the Nt targets coordinates\n",
    "    n_r_koors = torch.zeros((r_kcoors.shape), dtype=torch.float)\n",
    "    n_r_koors[:,:,0] = normalize(r_kcoors[:,:,0], width)\n",
    "    n_r_koors[:,:,1] = normalize(r_kcoors[:,:,1], height)\n",
    "    n_r_koors[:,:,2] = normalize(r_kcoors[:,:,2], n_slices)\n",
    "    n_r_koors[:,:,3] = normalize(r_kcoors[:,:,3], n_coils)\n",
    "    \n",
    "    return n_r_koors, n_r_patch, Nn\n",
    "\n",
    "\n",
    "class get_patch:\n",
    "    def __init__(\n",
    "        self, \n",
    "        width = 320,\n",
    "        height = 320,\n",
    "        patch_size=9, \n",
    "        ):\n",
    "        \n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, batch_coors: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Returns the 3x3 neighbors for all points in a batch.\n",
    "        Inputs : \n",
    "        - batch_coors : matrix of dimension batch_size x 4 denormalized coordinates (kx,ky,kz,coilid)\n",
    "        \"\"\"\n",
    "        \n",
    "        shifts = torch.tensor([[-1, -1], [0, -1], [1, -1],\n",
    "                [ -1, 0], [ 1, 0],\n",
    "                [ -1, 1], [ 0, 1], [ 1, 1]], device=batch_coors.device)  \n",
    "\n",
    "        # Extract kx, ky from k_coor\n",
    "        kx = batch_coors[:,:,0][:,0].unsqueeze(1)  # shape: (batch_size, 1)\n",
    "        ky = batch_coors[:,:,1][:,1].unsqueeze(1)  # shape: (batch_size, 1)\n",
    "        kz = batch_coors[:,:,2][:,0].unsqueeze(1)  # shape: (batch_size, 1)\n",
    "        \n",
    "        # Compute all neighbor shifts at once (apply shifts to kx, ky)\n",
    "        kx_neighbors = torch.clamp(kx + shifts[:, 0], 0, self.width - 1)\n",
    "        ky_neighbors = torch.clamp(ky + shifts[:, 1], 0, self.height - 1)\n",
    "        \n",
    "        # Ouput of neighbors dim : batch_size x nneighbors x 3 coordinates (kx, ky, kz)\n",
    "        neighbors = torch.stack([kx_neighbors, ky_neighbors, kz.repeat(1, self.patch_size-1)], dim=-1)\n",
    "        return neighbors\n",
    "    \n",
    "    def __call__(self, batch_coors: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(batch_coors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the grid for computing PISCO \n",
    "dataloader = DataLoader(dataset, batch_size=120000, shuffle=True, pin_memory=False)\n",
    "count = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_coils = 4\n",
    "n_slices = 3\n",
    "width = 320\n",
    "height = 320\n",
    "\n",
    "for inputs, targets in dataloader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    count += 1\n",
    "    if count > 1:\n",
    "        break\n",
    "\n",
    "k_coors = torch.zeros((inputs.shape[0], 4), dtype=torch.float)\n",
    "k_coors[:,0] = denormalize(inputs[:,0], width)\n",
    "k_coors[:,1] = denormalize(inputs[:,1], height)\n",
    "k_coors[:,2] = denormalize(inputs[:,2], n_slices)\n",
    "k_coors[:,3] = denormalize(inputs[:,3], n_coils)\n",
    "\n",
    "\n",
    "# Remove the edges \n",
    "leftmost_vedge = (k_coors[:, 1] == 0)\n",
    "rightmost_vedge = (k_coors[:, 1] == 319)\n",
    "upmost_vedge = (k_coors[:, 0] == 0)\n",
    "downmost_vedge = (k_coors[:, 0] == 319)\n",
    "\n",
    "edges = leftmost_vedge | rightmost_vedge | upmost_vedge | downmost_vedge\n",
    "k_nedge = k_coors[~edges]\n",
    "\n",
    "# #### Reshape:\n",
    "# # Reshape input matrixes for coilID to be considered dim : n_points x N_coils x 4\n",
    "r_kcoors = np.repeat(k_nedge[:, np.newaxis, :], n_coils, axis=1)\n",
    "r_kcoors[...,-1] = torch.arange(n_coils)\n",
    "\n",
    "# ##### Reshape patches matrix to : n_points x n_neighbours x N_coils x 4\n",
    "build_neighbours = get_patch()\n",
    "patch_coors = build_neighbours(r_kcoors)\n",
    "\n",
    "# Reshape so that dim : n_points x N_n x Nc x 4 (kx,ky,kz, n_coils coordinates)\n",
    "r_patch = torch.zeros((patch_coors.shape[0],patch_coors.shape[1], r_kcoors.shape[2]))\n",
    "r_patch[...,:3] = patch_coors\n",
    "r_patch = np.repeat(r_patch[:, :, np.newaxis], n_coils, axis=2)\n",
    "r_patch[...,-1] = torch.arange(n_coils)\n",
    "\n",
    "### For predicting, normalize coordinates back to [-1,1]\n",
    "# Normalize the NP neighbourhood coordinates\n",
    "n_r_patch = torch.zeros((r_patch.shape), dtype=torch.float)\n",
    "n_r_patch[:,:,:,0] = normalize(r_patch[:,:,:,0], width)\n",
    "n_r_patch[:,:,:,1] = normalize(r_patch[:,:,:,1], height)\n",
    "n_r_patch[:,:,:,2] = normalize(r_patch[:,:,:,2], n_slices)\n",
    "n_r_patch[:,:,:,3] = normalize(r_patch[:,:,:,3], n_coils)\n",
    "# Flatten the first dimensions for the purpose of kvalue prediction\n",
    "Nn = n_r_patch.shape[1]\n",
    "n_r_patch = n_r_patch.view(-1, n_coils, 4)\n",
    "\n",
    "# Normalize the Nt targets coordinates\n",
    "n_r_koors = torch.zeros((r_kcoors.shape), dtype=torch.float)\n",
    "n_r_koors[:,:,0] = normalize(r_kcoors[:,:,0], width)\n",
    "n_r_koors[:,:,1] = normalize(r_kcoors[:,:,1], height)\n",
    "n_r_koors[:,:,2] = normalize(r_kcoors[:,:,2], n_slices)\n",
    "n_r_koors[:,:,3] = normalize(r_kcoors[:,:,3], n_coils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(r_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "model = Siren()\n",
    "size_minibatch = 1000\n",
    "\n",
    "t_predicted = torch.zeros((n_r_koors.shape[0], n_coils), dtype=torch.complex64)\n",
    "patch_predicted = torch.zeros((n_r_patch.shape[0], n_coils), dtype=torch.complex64)\n",
    "\n",
    "for coil_id in range(n_coils):\n",
    "    t_predicted[:,coil_id] = torch.view_as_complex(model(n_r_koors[:,coil_id,:]))\n",
    "    patch_predicted[:,coil_id] = torch.view_as_complex(model(n_r_patch[:,coil_id,:]))\n",
    "\n",
    "# # Reshape back the patches_matrix\n",
    "patch_predicted = patch_predicted.view(n_r_koors.shape[0], Nn, n_coils)\n",
    "\n",
    "# size_minibatch = 300\n",
    "T_s, Ns = split_batch(t_predicted, size_minibatch)\n",
    "P_s, Ns = split_batch(patch_predicted, size_minibatch)\n",
    "\n",
    "\n",
    "# ######## Here compute the Lpisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j],\n",
       "        [-0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j],\n",
       "        [-0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j],\n",
       "        ...,\n",
       "        [-0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j],\n",
       "        [-0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j],\n",
       "        [-0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j, -0.0218+0.0151j]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_s[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "\n",
      "torch.Size([32, 4])\n",
      "tensor(1.9872e-05, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## L pisco\n",
    "##################################\n",
    "alpha = 1.e-4\n",
    "Ws = []\n",
    "\n",
    "# Generate the list of Ws from the subset of minibatches \n",
    "for i, t_s in enumerate(T_s):\n",
    "    p_s = P_s[i]\n",
    "    p_s = torch.flatten(p_s, start_dim=1)\n",
    "    print()\n",
    "    ws = compute_Lsquares(p_s, t_s, alpha)\n",
    "    print(ws.shape)\n",
    "    Ws.append(ws)\n",
    "\n",
    "\n",
    "pisco_loss = L_pisco (Ws) # Ws is a list of Ws' from the minibatches\n",
    "\n",
    "print(pisco_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0020, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Measure distortion in Ws\n",
    "tensor_magnitudes = [torch.abs(tensor) for tensor in Ws]\n",
    "stacked_tensors = torch.stack(tensor_magnitudes)\n",
    "std_dev_across_tensors = torch.std(stacked_tensors, dim=0)\n",
    "torch.norm(std_dev_across_tensors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytcu11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

seed: 7


path_to_outputs: /scratch_net/ken/mcrespo/proj_marina/logs/30_10/ # TODO: SET.

wandb:
  project_name: "MultiSlicePisco"

# model_checkpoint: ./logs/3_10/10-03_16h38m/epoch_1999.pt  # TODO: SET (OR LEAVE COMMENTED).

dataset:
  # path_to_data: /itet-stor/mcrespo/bmicdatasets-originals/Originals/fastMRI/brain/multicoil_train/file_brain_AXFLAIR_200_6002435.h5 # TODO: SET.
  path_to_data: /itet-stor/mcrespo/bmicdatasets-originals/Originals/fastMRI/brain/multicoil_train/file_brain_AXT1POST_203_6000861.h5
  n_slices: 3 
  with_mask: True
  acceleration: 3
  center_frac: 0.15
  mask_type: Random
  # center_train: True
  center_train: False
  # epsilon: 1.e-10 #NOTE this parameter is used for appliying the logarithmic transformation

dataset_full:
  # path_to_data: /itet-stor/mcrespo/bmicdatasets-originals/Originals/fastMRI/brain/multicoil_train/file_brain_AXFLAIR_200_6002435.h5 # TODO: SET.
  path_to_data: /itet-stor/mcrespo/bmicdatasets-originals/Originals/fastMRI/brain/multicoil_train/file_brain_AXT1POST_203_6000861.h5
  n_slices: 3 
  with_mask: False
  acceleration: 3
  center_frac: 0.15
  mask_type: Equispaced
  # center_train: True
  center_train: False
  epsilon: 1.e-10 #NOTE this parameter is used for appliying the logarithmic transformation

dataloader:
  batch_size: 12_000
  pin_memory: False 

# model:
#   id: Siren3.0
#   params:
#     hidden_dim: 512
#     embedding_dim: 10
#     n_layers: 4

model:
  id: Siren4.0
  params:
    hidden_dim: 512
    levels: 10
    n_layers: 4

loss:
  id: MSE
  params:
    gamma: 1 # Scalar value that gets multiplied to the real loss value
    # epsilon: 1.e-8
    # sigma: 1.0
    # factor: 0.5

optimizer:
  id: Adam
  params:
    lr: 5.e-5 # The dot is necessary, otherwise the parser will mistake this for a string (and not a float).
    # weight_decay: 0.1
scheduler:
  id: StepLR
  params:
    gamma: 0.1
    step_size: 4000

# Training Process
n_epochs: 2000
log_interval: 100

l_pisco:
  # addpisco: True
  addpisco: False
  E_epoch: 1300
  minibatch_size: 1000 
  alpha: 1.e-4 # Regularizer for the W
  factor: 0.1 # How much the Lpisco loss gets weighted


###################################################
# INFORMATION ONLY - NO EFFECT ON RUN
###################################################
# The following section is for documentation purposes only.
# It does not affect the actual behavior of the run.
# These values are used solely for Tensorboard output, to help identify run types.
hparam_info:
  # dataset: "undersampled (except center)"
  dataset: "all data (except center)"

  # observation_type: "train sample"
  observation_type: "test sample"

  # regularization: "None"
  # regularization: "layer norm"
  # regularization: "weight norm"
  # regularization: "AdamW (weight decay)"

  coord_encoding: "positional encoding L=15"
  # coord_encoding: "fourier_feat"

  # normalization: "None"
  normalization: "divide by .999 abs quantile"
  # normalization: "divide by max modulus"
  # normalization: ".05 / .95 real and imag parts"
  # normalization: "min/max real and imag parts"
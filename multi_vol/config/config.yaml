seed: 7

runtype: train
# runtype: test

path_to_outputs: # TODO: SET.

# model_checkpoint: path_to_checkpoint/epoch_1999.pt  # TODO: SET (OR LEAVE COMMENTED).

dataset:
  path_to_data: # TODO: SET.
  n_volumes: 3
  n_slices: 2
  with_mask: True  # NOTE: During training phase, set to False.
  acceleration: 4
  center_frac: 0.15

dataloader:
  batch_size: 120_000
  pin_memory: False

model:
  id: Siren
  params:
    coord_dim: 4
    embedding_dim: 512
    hidden_dim: 512
    L: 10
    n_layers: 8
    # dropout_rate: 0.2

loss:
  id: MSEL2
  params:
    gamma: 0.1
    sigma: 0.01

optimizer:
  id: Adam
  params:
    lr: 5.e-6 # The dot is necessary, otherwise the parser will mistake this for a string (and not a float).

scheduler:
  id: StepLR
  params:
    gamma: 1.0
    step_size: 20_000

# Training Process
n_epochs: 1_000
log_interval: 100
checkpoint_interval: 500  # Keep in mind that each checkpoint takes ~241 MB of space.


###################################################
# INFORMATION ONLY - NO EFFECT ON RUN
###################################################
# The following section is for documentation purposes only.
# It does not affect the actual behavior of the run.
# These values are used solely for Tensorboard output, to help identify run types.
hparam_info:
  # dataset: "undersampled (except center)"
  dataset: "all data (except center)"

  # observation_type: "train sample"
  observation_type: "test sample"

  # regularization: "None"
  # regularization: "layer norm"
  # regularization: "weight norm"
  # regularization: "AdamW (weight decay)"

  coord_encoding: "positional encoding"
  # coord_encoding: "fourier_feat"

  # normalization: "None"
  normalization: "divide by .999 abs quantile"
  # normalization: "divide by max modulus"
  # normalization: ".05 / .95 real and imag parts"
  # normalization: "min/max real and imag parts"
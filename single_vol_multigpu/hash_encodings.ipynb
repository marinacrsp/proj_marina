{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Embedding(400, 2)\n",
      "  (1): Embedding(676, 2)\n",
      "  (2): Embedding(1225, 2)\n",
      "  (3): Embedding(2209, 2)\n",
      "  (4-9): 6 x Embedding(4096, 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "L = 10\n",
    "n_inputs_dim = 2\n",
    "log2_hashmap_size = 12 # NOTE : This is the size of the hashtable (T)\n",
    "\n",
    "n_features_per_level = 2\n",
    "Nmax = 320\n",
    "Nmin = 16\n",
    "\n",
    "b = np.exp((np.log(Nmax)-np.log(Nmin))/(L-1))\n",
    "\n",
    "def _get_number_of_embeddings(level_idx: int) -> int:\n",
    "    \"\"\"\n",
    "    level_idx: level index\n",
    "    returns: number of embeddings for given level. Max number is 2**self.log2_hashmap_size\n",
    "    \"\"\"\n",
    "\n",
    "    max_size = 2**log2_hashmap_size\n",
    "\n",
    "    resolution = int(Nmin * (b**level_idx).item())\n",
    "    \n",
    "    n_level_size = (resolution + 4) ** 2  # see explanation below at 'def _to_1D(...)' why we do + 2\n",
    "\n",
    "    return min(max_size, n_level_size)\n",
    "\n",
    "embeddings = nn.ModuleList(\n",
    "    [\n",
    "        nn.Embedding(\n",
    "            _get_number_of_embeddings([i]), n_features_per_level\n",
    "        )\n",
    "        for i in range(L)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(embeddings)\n",
    "\n",
    "\n",
    "#### Functions required for hash_encoding\n",
    "\n",
    "def bilinear_interp(\n",
    "    x: torch.Tensor,\n",
    "    box_indices: torch.Tensor,\n",
    "    box_embedds: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Function that computes the bilinear interpolation of the embedding for a point in a bounding box of identified corners\n",
    "    \"\"\"\n",
    "    if box_indices.shape[0] > 2:\n",
    "        w11 = np.linalg.norm(box_indices[0] - x)\n",
    "        w12 = np.linalg.norm(box_indices[1] - x)\n",
    "        w21 = np.linalg.norm(box_indices[2] - x)\n",
    "        w22 = np.linalg.norm(box_indices[3] - x)\n",
    "\n",
    "        den = w11+w12+w21+w22\n",
    "\n",
    "        w11 /= den\n",
    "        w12 /= den\n",
    "        w21 /= den\n",
    "        w22 /= den\n",
    "\n",
    "        xi_embedding = w11*box_embedds[0] + w12*box_embedds[1] + w21*box_embedds[2] + w22*box_embedds[3]  \n",
    "        \n",
    "    else:\n",
    "        xi_embedding = box_embedds\n",
    "        \n",
    "    return xi_embedding\n",
    "\n",
    "\n",
    "def _get_box_idx (point, Nmax, resolution, log2_hashmap_size):\n",
    "    x, y = point\n",
    "\n",
    "    if Nmax == resolution:\n",
    "        box_idx = torch.tensor((point[0], point[1]))\n",
    "\n",
    "    else:\n",
    "        # Calculate box size based on the total boxes\n",
    "        box_width = Nmax // resolution  # Width of each box\n",
    "        box_height = Nmax // resolution  # Height of each box\n",
    "\n",
    "        x_min = max(0, (x // box_width) * box_width)\n",
    "        y_min = max(0, (y // box_height) * box_height)\n",
    "        x_max = min(Nmax, x_min + box_width)\n",
    "        y_max = min(Nmax, y_min + box_height)\n",
    "        \n",
    "        \n",
    "        p00 = [x_min, y_min]\n",
    "        p01 = [x_max, y_min]\n",
    "        p10 = [x_min, y_max]\n",
    "        p11 = [x_max, y_max]\n",
    "        \n",
    "        box_idx = torch.tensor((p00, p01, p10, p11))\n",
    "        \n",
    "    max_hashtable_size = 2**log2_hashmap_size\n",
    "    if max_hashtable_size >= (resolution+4)**2:\n",
    "        hashed_box_idx, scaled_coords = _to_1D(box_idx, Nmax, resolution)\n",
    "    else:\n",
    "        hashed_box_idx = _hash(box_idx, log2_hashmap_size)\n",
    "        scaled_coords = box_idx\n",
    "    return box_idx, scaled_coords, hashed_box_idx\n",
    "    # return box_idx\n",
    "\n",
    "def _to_1D(coors, Nmax, resolution):\n",
    "    scale_factor = Nmax // resolution\n",
    "    scaled_coords = torch.div(coors, scale_factor, rounding_mode=\"floor\").int()    \n",
    "    x = scaled_coords[:,0]\n",
    "    y = scaled_coords[:,1]\n",
    "    \n",
    "    return (y * resolution + x), scaled_coords\n",
    "\n",
    "def _hash(coords: torch.Tensor, log2_hashmap_size: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    coords: this function can process upto 7 dim coordinates\n",
    "    log2T:  logarithm of T w.r.t 2\n",
    "    \"\"\"\n",
    "    primes = torch.tensor([\n",
    "        1,\n",
    "        2654435761,\n",
    "        805459861,\n",
    "        3674653429,\n",
    "        2097192037,\n",
    "        1434869437,\n",
    "        2165219737,\n",
    "    ], dtype = torch.int64\n",
    "    )\n",
    "\n",
    "    xor_result = torch.zeros_like(coords, dtype=torch.int64)[..., 0]\n",
    "    for i in range(coords.shape[-1]): # Loop around all possible dimensions of the vector containing the bounding box positions\n",
    "        xor_result ^= coords[...,i].to(torch.int64)*primes[i]\n",
    "\n",
    "    return (\n",
    "        torch.tensor((1 << log2_hashmap_size) - 1, device=xor_result.device)\n",
    "        & xor_result\n",
    "        )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 400\n",
      "19 529\n",
      "24 784\n",
      "30 1156\n",
      "37 1681\n",
      "46 2500\n",
      "57 3721\n",
      "71 5625\n",
      "88 8464\n",
      "109 12769\n",
      "135 19321\n",
      "168 29584\n",
      "208 44944\n",
      "258 68644\n",
      "320 104976\n"
     ]
    }
   ],
   "source": [
    "for i in range(L):\n",
    "    Nl = int(Nmin*b**i)\n",
    "    max_size = (Nl+4)**2\n",
    "    print(Nl, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "div() received an invalid combination of arguments - got (tuple, int, rounding_mode=str), but expected one of:\n * (Tensor input, Tensor other, *, Tensor out = None)\n * (Tensor input, Tensor other, *, str rounding_mode, Tensor out = None)\n * (Tensor input, Number other, *, str rounding_mode)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m coors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([i,j])\n\u001b[1;32m      6\u001b[0m box_idx \u001b[38;5;241m=\u001b[39m _get_box_idx(coors, \u001b[38;5;241m320\u001b[39m, Nl, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m hashed \u001b[38;5;241m=\u001b[39m _to_1D(box_idx, \u001b[38;5;241m320\u001b[39m, Nl)\n",
      "Cell \u001b[0;32mIn[3], line 103\u001b[0m, in \u001b[0;36m_to_1D\u001b[0;34m(coors, Nmax, resolution)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_1D\u001b[39m(coors, Nmax, resolution):\n\u001b[1;32m    102\u001b[0m     scale_factor \u001b[38;5;241m=\u001b[39m Nmax \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m resolution\n\u001b[0;32m--> 103\u001b[0m     scaled_coords \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiv(coors, scale_factor, rounding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mint()    \n\u001b[1;32m    104\u001b[0m     x \u001b[38;5;241m=\u001b[39m scaled_coords[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    105\u001b[0m     y \u001b[38;5;241m=\u001b[39m scaled_coords[:,\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: div() received an invalid combination of arguments - got (tuple, int, rounding_mode=str), but expected one of:\n * (Tensor input, Tensor other, *, Tensor out = None)\n * (Tensor input, Tensor other, *, str rounding_mode, Tensor out = None)\n * (Tensor input, Number other, *, str rounding_mode)\n"
     ]
    }
   ],
   "source": [
    "Nl = 16\n",
    "all_hash = []\n",
    "for i in range(30):\n",
    "    for j in range(30):\n",
    "        coors = torch.tensor([i,j])\n",
    "        box_idx = _get_box_idx(coors, 320, Nl, 12)\n",
    "        hashed = _to_1D(box_idx, 320, Nl)\n",
    "        # print(hashed)\n",
    "        # all_hash.append({'box_idx': box_idx, 'hashed': hashed, 'coors': coors} )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 20.,  80.],\n",
      "        [ 40.,  80.],\n",
      "        [ 20., 100.],\n",
      "        [ 40., 100.]], dtype=torch.float64)\n",
      "tensor([65, 66, 81, 82], dtype=torch.int32)\n",
      "tensor([[14., 84.],\n",
      "        [28., 84.],\n",
      "        [14., 98.],\n",
      "        [28., 98.]], dtype=torch.float64)\n",
      "tensor([133, 134, 155, 156], dtype=torch.int32)\n",
      "tensor([[20., 80.],\n",
      "        [30., 80.],\n",
      "        [20., 90.],\n",
      "        [30., 90.]], dtype=torch.float64)\n",
      "tensor([250, 251, 281, 282], dtype=torch.int32)\n",
      "tensor([[21., 84.],\n",
      "        [28., 84.],\n",
      "        [21., 91.],\n",
      "        [28., 91.]], dtype=torch.float64)\n",
      "tensor([519, 520, 562, 563], dtype=torch.int32)\n",
      "tensor([[25., 85.],\n",
      "        [30., 85.],\n",
      "        [25., 90.],\n",
      "        [30., 90.]], dtype=torch.float64)\n",
      "tensor([2012, 2011, 2083, 2084])\n",
      "tensor([[24., 87.],\n",
      "        [27., 87.],\n",
      "        [24., 90.],\n",
      "        [27., 90.]], dtype=torch.float64)\n",
      "tensor([2879, 2876, 2082, 2081])\n",
      "tensor([[24., 86.],\n",
      "        [26., 86.],\n",
      "        [24., 88.],\n",
      "        [26., 88.]], dtype=torch.float64)\n",
      "tensor([ 366,  364, 1216, 1218])\n",
      "tensor([[25., 87.],\n",
      "        [26., 87.],\n",
      "        [25., 88.],\n",
      "        [26., 88.]], dtype=torch.float64)\n",
      "tensor([2878, 2877, 1217, 1218])\n",
      "tensor([[25., 87.],\n",
      "        [26., 87.],\n",
      "        [25., 88.],\n",
      "        [26., 88.]], dtype=torch.float64)\n",
      "tensor([2878, 2877, 1217, 1218])\n",
      "tensor([25., 87.], dtype=torch.float64)\n",
      "tensor(2878)\n",
      "tensor([[ 0.9333, -0.1295, -0.9597,  1.2396,  1.4317,  2.4286,  3.0751,  0.5779,\n",
      "         -0.9268, -1.2909,  0.0665, -2.3448, -0.0658,  0.6345,  1.6719, -0.0266,\n",
      "          2.1433,  1.3595,  0.9814,  0.5604],\n",
      "        [ 0.9202, -0.1230, -0.9949,  1.2618,  1.3843,  2.4319,  3.1361,  0.5885,\n",
      "         -0.8829, -1.3146, -0.0616, -2.4632, -1.1216,  1.4720, -0.0801, -1.4687,\n",
      "          0.8751,  2.6094,  0.5368,  0.4467]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from hash_encoding_batch import *\n",
    "point = torch.tensor(([25,87], [26, 87]), dtype=float)\n",
    "x_embedded_all = []\n",
    "embedder = hash_encoder(levels=15, log2_hashmap_size=12, n_features_per_level=2, n_max=320, n_min=16)\n",
    "weights_all = []\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    box_idx, hashed_box_idx = embedder._get_box_idx(point, n_l=resolution)\n",
    "    print(box_idx[0])\n",
    "    print(hashed_box_idx[0])\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded, weights = embedder.bilinear_interp(point, box_idx, box_embedds)\n",
    "    weights_all.append(weights)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "    \n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8540, 0.7191, 0.7637, 0.6632],\n",
       "        [0.8418, 0.7315, 0.7544, 0.6723]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15, 15],\n",
      "        [16, 15],\n",
      "        [15, 16],\n",
      "        [16, 16]], dtype=torch.int32)\n",
      "tensor([255, 256, 271, 272], dtype=torch.int32)\n",
      "tensor([[19, 19],\n",
      "        [20, 19],\n",
      "        [19, 20],\n",
      "        [20, 20]], dtype=torch.int32)\n",
      "tensor([380, 381, 399, 400], dtype=torch.int32)\n",
      "tensor([[24, 24],\n",
      "        [24, 24],\n",
      "        [24, 24],\n",
      "        [24, 24]], dtype=torch.int32)\n",
      "tensor([600, 600, 600, 600], dtype=torch.int32)\n",
      "tensor([[31, 31],\n",
      "        [32, 31],\n",
      "        [31, 32],\n",
      "        [32, 32]], dtype=torch.int32)\n",
      "tensor([961, 962, 991, 992], dtype=torch.int32)\n",
      "tensor([[39, 39],\n",
      "        [40, 39],\n",
      "        [39, 40],\n",
      "        [40, 40]], dtype=torch.int32)\n",
      "tensor([1482, 1483, 1519, 1520], dtype=torch.int32)\n",
      "tensor([[53, 53],\n",
      "        [53, 53],\n",
      "        [53, 53],\n",
      "        [53, 53]], dtype=torch.int32)\n",
      "tensor([2491, 2491, 2491, 2491], dtype=torch.int32)\n",
      "tensor([[63, 63],\n",
      "        [64, 63],\n",
      "        [63, 64],\n",
      "        [64, 64]], dtype=torch.int32)\n",
      "tensor([3654, 3655, 3711, 3712], dtype=torch.int32)\n",
      "tensor([[316, 316],\n",
      "        [320, 316],\n",
      "        [316, 320],\n",
      "        [320, 320]])\n",
      "tensor([1856, 1852, 3196, 3072])\n",
      "tensor([[318, 318],\n",
      "        [320, 318],\n",
      "        [318, 320],\n",
      "        [320, 320]])\n",
      "tensor([2272, 2206, 3198, 3072])\n",
      "tensor([[318, 318],\n",
      "        [320, 318],\n",
      "        [318, 320],\n",
      "        [320, 320]])\n",
      "tensor([2272, 2206, 3198, 3072])\n",
      "tensor([[318, 318],\n",
      "        [320, 318],\n",
      "        [318, 320],\n",
      "        [320, 320]])\n",
      "tensor([2272, 2206, 3198, 3072])\n",
      "tensor([[319, 319],\n",
      "        [320, 319],\n",
      "        [319, 320],\n",
      "        [320, 320]])\n",
      "tensor([ 688,  719, 3199, 3072])\n",
      "tensor([[319, 319],\n",
      "        [320, 319],\n",
      "        [319, 320],\n",
      "        [320, 320]])\n",
      "tensor([ 688,  719, 3199, 3072])\n",
      "tensor([[319, 319],\n",
      "        [320, 319],\n",
      "        [319, 320],\n",
      "        [320, 320]])\n",
      "tensor([ 688,  719, 3199, 3072])\n",
      "tensor([319, 319])\n",
      "tensor(688)\n",
      "tensor([ 0.5627,  0.4360,  0.3523, -0.3510,  0.8703, -0.9810, -0.1174, -0.4391,\n",
      "         0.0131, -0.3936,  0.8818, -0.0412, -0.7772,  0.3465, -0.3624, -0.3806,\n",
      "        -0.4110,  0.0723, -0.7719, -0.3013, -0.0670,  0.1906, -0.4856, -0.3593,\n",
      "        -0.8881, -0.1183, -0.4982, -0.2763,  1.6006,  1.0697],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "point = torch.tensor([319,319])\n",
    "x_embedded_all = []\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    # print(resolution)\n",
    "    box_idx, scaled_coords, hashed_box_idx = _get_box_idx(point, Nmax, resolution, log2_hashmap_size)\n",
    "    print(scaled_coords)\n",
    "    print(hashed_box_idx)\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded = bilinear_interp(point, box_idx, box_embedds)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "22\n",
      "31\n",
      "43\n",
      "60\n",
      "84\n",
      "117\n",
      "164\n",
      "229\n",
      "320\n",
      "tensor([ 0.4948, -0.6677,  0.4109,  1.1651,  0.6012, -0.9509, -1.4937,  0.5453,\n",
      "        -0.3050, -0.0969, -0.9447, -0.5184, -0.6131, -0.4333,  1.2609, -0.0287,\n",
      "        -0.6124, -0.7133, -0.8770,  2.7351], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "point = torch.tensor([310, 317])\n",
    "x_embedded_all = []\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    print(resolution)\n",
    "    box_idx, hashed_box_idx = _get_box_idx(point, Nmax, resolution, log2_hashmap_size)\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded = bilinear_interp(point, box_idx, box_embedds)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "22\n",
      "31\n",
      "43\n",
      "60\n",
      "84\n",
      "117\n",
      "164\n",
      "229\n",
      "320\n",
      "tensor([ 0.8431,  0.2460,  0.4135,  0.3757, -0.2419, -0.0620, -0.4686, -1.2061,\n",
      "        -0.0622,  0.1241,  0.3490,  1.3119,  0.0768, -0.1606,  0.4591, -0.5743,\n",
      "        -0.2125,  0.3595,  0.7171, -2.1822], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "point = torch.tensor([0, 0])\n",
    "x_embedded_all = []\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    print(resolution)\n",
    "    box_idx, hashed_box_idx = _get_box_idx(point, Nmax, resolution, log2_hashmap_size)\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded = bilinear_interp(point, box_idx, box_embedds)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7580, 0.0689],\n",
      "        [0.4019, 0.2114],\n",
      "        [0.8250, 0.1597],\n",
      "        [0.3326, 0.7257],\n",
      "        [0.2233, 0.3285],\n",
      "        [0.3154, 0.6191],\n",
      "        [0.0753, 0.6940],\n",
      "        [0.9564, 0.2477],\n",
      "        [0.5836, 0.0924],\n",
      "        [0.4902, 0.1884],\n",
      "        [0.4021, 0.0060],\n",
      "        [0.4242, 0.0730],\n",
      "        [0.3489, 0.2683],\n",
      "        [0.3255, 0.8294],\n",
      "        [0.1232, 0.3607],\n",
      "        [0.8837, 0.5485],\n",
      "        [0.6858, 0.8674],\n",
      "        [0.1638, 0.1519],\n",
      "        [0.6985, 0.1344],\n",
      "        [0.6996, 0.6958]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "point = torch.rand(20,2)\n",
    "x_embedded_all = []\n",
    "print(point)\n",
    "for i in range(L):\n",
    "    \n",
    "    resolution = int(Nmin * b**i)\n",
    "    print(resolution)\n",
    "    box_idx, hashed_box_idx = _get_box_idx(point, Nmax, resolution, log2_hashmap_size)\n",
    "    box_embedds = embeddings[i](hashed_box_idx)\n",
    "    x_embedded = bilinear_interp(point, box_idx, box_embedds)\n",
    "    x_embedded_all.append(x_embedded)\n",
    "\n",
    "x1 = torch.cat(x_embedded_all, dim=-1)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New level: \n",
      " tensor([[100,   0],\n",
      "        [120,   0],\n",
      "        [100,  20],\n",
      "        [120,  20]])\n",
      "tensor([[5, 0],\n",
      "        [6, 0],\n",
      "        [5, 1],\n",
      "        [6, 1]], dtype=torch.int32)\n",
      "New level: \n",
      " tensor([[ 98,   0],\n",
      "        [112,   0],\n",
      "        [ 98,  14],\n",
      "        [112,  14]])\n",
      "tensor([[7, 0],\n",
      "        [8, 0],\n",
      "        [7, 1],\n",
      "        [8, 1]], dtype=torch.int32)\n",
      "New level: \n",
      " tensor([[100,  10],\n",
      "        [110,  10],\n",
      "        [100,  20],\n",
      "        [110,  20]])\n",
      "tensor([[10,  1],\n",
      "        [11,  1],\n",
      "        [10,  2],\n",
      "        [11,  2]], dtype=torch.int32)\n",
      "New level: \n",
      " tensor([[ 98,   7],\n",
      "        [105,   7],\n",
      "        [ 98,  14],\n",
      "        [105,  14]])\n",
      "tensor([[14,  1],\n",
      "        [15,  1],\n",
      "        [14,  2],\n",
      "        [15,  2]], dtype=torch.int32)\n",
      "New level: \n",
      " tensor([[100,  10],\n",
      "        [105,  10],\n",
      "        [100,  15],\n",
      "        [105,  15]])\n",
      "tensor([[20,  2],\n",
      "        [21,  2],\n",
      "        [20,  3],\n",
      "        [21,  3]], dtype=torch.int32)\n",
      "New level: \n",
      " tensor([[ 99,   9],\n",
      "        [102,   9],\n",
      "        [ 99,  12],\n",
      "        [102,  12]])\n",
      "tensor([[ 99,   9],\n",
      "        [102,   9],\n",
      "        [ 99,  12],\n",
      "        [102,  12]])\n",
      "New level: \n",
      " tensor([[100,  10],\n",
      "        [102,  10],\n",
      "        [100,  12],\n",
      "        [102,  12]])\n",
      "tensor([[100,  10],\n",
      "        [102,  10],\n",
      "        [100,  12],\n",
      "        [102,  12]])\n",
      "New level: \n",
      " tensor([[100,  10],\n",
      "        [101,  10],\n",
      "        [100,  11],\n",
      "        [101,  11]])\n",
      "tensor([[100,  10],\n",
      "        [101,  10],\n",
      "        [100,  11],\n",
      "        [101,  11]])\n",
      "New level: \n",
      " tensor([[100,  10],\n",
      "        [101,  10],\n",
      "        [100,  11],\n",
      "        [101,  11]])\n",
      "tensor([[100,  10],\n",
      "        [101,  10],\n",
      "        [100,  11],\n",
      "        [101,  11]])\n",
      "New level: \n",
      " tensor([100,  10])\n",
      "tensor([100,  10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.4597,  0.1142, -0.4894, -0.3159,  0.9899, -0.7720, -0.0278, -0.5469,\n",
       "        -0.8895,  0.9419, -0.4393,  0.3824,  0.3304, -0.2077,  0.2283, -0.1087,\n",
       "        -0.3258, -0.5330, -0.6824, -0.3033], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hash_encoding import *\n",
    "point = torch.tensor([100,10])\n",
    "\n",
    "embedder = hash_encoder(levels=10, log2_hashmap_size=12, n_features_per_level=2, n_max = 320, n_min = 16)\n",
    "\n",
    "embedder(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytcu11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
